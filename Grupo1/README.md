# **EQUILIBRANDO CLASSES**
## *TÃ‰CNICAS PARA TRATAR DADOS DESBALANCEADOS EM MACHINE LEARNING*

Esse repositÃ³rio foi voltado para o desenvolvimento de um projeto prÃ¡tico para a entidade estudantil Hype. O objetivo dele foi, atravÃ©s de mÃ©todos de balanceamento, melhorar os resultados dos modelos.

---------------------------------------------------------
## Tecnologias
Foram usado Python com as bibliotecas: openpyxl (criar editar planilhas excel), imblearn (para os mÃ©todos de balanceamento), sklearn (para a criaÃ§Ã£o dos modelos de machine learning), pandas (para abertura, leitura e anÃ¡lsie de base de dados), matplotlib e seaborn (para criaÃ§Ã£o dos grÃ¡ficos), kagglehub (importaÃ§Ã£o do dataset) e os (criaÃ§Ã£o e ediÃ§Ã£o de pastas).

> !pip install openpyxl imblearn sklearn pandas matplotlib seaborn kagglehub os

Foi usado o dataset [Credit Card Fraud Detection (DetecÃ§Ã£o de Fraude de CartÃ£o de CrÃ©dito)](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?utm_source), retirado da plataforma Kaggle. Nele hÃ¡ dados de 284.807 transaÃ§Ãµes, em que apenas 492 sÃ£o fraudes, ou seja, 0,172% da base de dados inteira.

Os modelos sÃ£o criados e treinados usando os dados desbalanceados e balanceados. Ainda Ã© impresso na tela as mÃ©tricas dos modelos e os grÃ¡ficos de AUC-ROC e Precission-Recall.

Ademais, os grÃ¡ficos sÃ£o salvos nas pastas.

    /projeto
    â”‚
    â”œâ”€â”€ modelos
    â”‚   â”œâ”€â”€ <modelo>
    â”‚   â”‚   â”œâ”€â”€ matriz-confusao-<modelo>-<mÃ©todo>.png
    â”‚   â”‚   â”œâ”€â”€ auc-roc-<modelo>-<mÃ©todo>.png
    â”‚   â”‚   â””â”€â”€ precision-recall-<modelo>-<mÃ©todo>.png
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ graphics
    â”‚   â”œâ”€â”€ countplot.png
    â”‚   â””â”€â”€ heatmap-corr.png
    â”‚
    |
    â”œâ”€â”€ resultados.xlsx
    â”‚
    â”œâ”€â”€ notebook-1.ipynb
    â””â”€â”€ notebook-2.ipynb

Recomenda-se usar ou o ***Jupyter*** ou ***Google Colab*** para a execuÃ§Ã£o do cÃ³digo.

Foram usado os mÃ©todos *SMOTE*, *Random Oversampling*, *Random Undersampling*, *ENN* e *SMOTE-ENN* para os testes.

De modelos, foram treinados e testados o *KNN* e *Logistic Regression*, modelo sensÃ­veis Ã  esses datasets, e *Random Forest*, que conseque lidar melhor, e comparados para ver suas diferenÃ§as.

notebook-1.ipynb => Neste foram usados os mÃ©todos SMOTE, ENN e SMOTE-ENN;\
notebook-2.ipynb => Neste foram usados os mÃ©todos SMOTE, Random Oversampling e Random Undersampling.


## ğŸ‘¤ Contribuidores

-   **[Caique SidrÃ£o](https://www.linkedin.com/in/caique-sidr%C3%A3o/)**
-   **[Gabriel Lima](https://www.linkedin.com/in/gabriel-costenaro-lima-6a5a2a356/)**
-   **[Rebecka Bocci](https://www.linkedin.com/in/rebecka-bocci-domingues-399157325/)**


## ğŸ“œ LicenÃ§a